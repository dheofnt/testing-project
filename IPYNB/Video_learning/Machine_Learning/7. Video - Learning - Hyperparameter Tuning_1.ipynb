{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- Analyze Bankloan.csv\r\n",
    "    - Features: Emploty, Debtinc, creddebt, othdebt\r\n",
    "    - Target: Default\r\n",
    "- Random state 2020, splitting 80:20 stratified\r\n",
    "1. Modeling compute accuracy, recall and another metrics using stratified CV 5 fold: \r\n",
    "    - a logistic regression(solver liblinear), \r\n",
    "    - b. KNN (K=5), \r\n",
    "    - c Tree (Criterion entropy, max_depth 5)\r\n",
    "2. Compute recall, precision, f1 score and make ROC, PRC from logistic regression (solver liblinear) in test\r\n",
    "3. Simple Hyperparameter tuning: (optimize c) optimized by f1 and using training 60% validation 20 and test 20%\r\n",
    "4. COmpalre the result (before and after)\r\n",
    "5. Grid Search CV Hyperparameter tuning: (Optimize c and max_iter) optimize by f1 and using stratified cv 5 fold\r\n",
    "6. compare the result before and after"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import category_encoders as ce\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\r\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, classification_report, f1_score\r\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve, precision_recall_curve, average_precision_score, plot_precision_recall_curve\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(r'C:\\Users\\dheof\\Desktop\\Help\\Purwadhika\\Csv_Files\\bankloan.csv')\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>debtinc</th>\n",
       "      <th>creddebt</th>\n",
       "      <th>othdebt</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>176</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.359392</td>\n",
       "      <td>5.008608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.362202</td>\n",
       "      <td>4.000798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>2.168925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>120</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.658720</td>\n",
       "      <td>0.821280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.787436</td>\n",
       "      <td>3.056564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.262062</td>\n",
       "      <td>0.979938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.369495</td>\n",
       "      <td>2.045505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.491264</td>\n",
       "      <td>1.940736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.302608</td>\n",
       "      <td>4.165392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.994684</td>\n",
       "      <td>3.473316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  ed  employ  address  income  debtinc   creddebt   othdebt  default\n",
       "0     41   3      17       12     176      9.3  11.359392  5.008608        1\n",
       "1     27   1      10        6      31     17.3   1.362202  4.000798        0\n",
       "2     40   1      15       14      55      5.5   0.856075  2.168925        0\n",
       "3     41   1      15       14     120      2.9   2.658720  0.821280        0\n",
       "4     24   2       2        0      28     17.3   1.787436  3.056564        1\n",
       "..   ...  ..     ...      ...     ...      ...        ...       ...      ...\n",
       "695   36   2       6       15      27      4.6   0.262062  0.979938        1\n",
       "696   29   2       6        4      21     11.5   0.369495  2.045505        0\n",
       "697   33   1      15        3      32      7.6   0.491264  1.940736        0\n",
       "698   45   1      19       22      77      8.4   2.302608  4.165392        0\n",
       "699   37   1      12       14      44     14.7   2.994684  3.473316        0\n",
       "\n",
       "[700 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA SPLITTING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "fitur = ['employ', 'debtinc', 'creddebt', 'othdebt']\r\n",
    "x = df[fitur]\r\n",
    "y = df['default']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "x_trainval, x_test, y_trainval, y_test = train_test_split(\r\n",
    "    x,\r\n",
    "    y,\r\n",
    "    stratify = y,\r\n",
    "    test_size = 0.2,\r\n",
    "    random_state = 2020\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "logreg = LogisticRegression(solver = 'liblinear', random_state=2020)\r\n",
    "knn = KNeighborsClassifier(n_neighbors= 5)\r\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth = 5, random_state=2020)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "skfold = StratifiedKFold(n_splits = 5)\r\n",
    "\r\n",
    "logreg_cv = cross_val_score(logreg, x_trainval, y_trainval, cv = skfold, scoring = 'f1')\r\n",
    "knn_cv = cross_val_score(knn, x_trainval, y_trainval, cv = skfold, scoring = 'f1', error_score= 'raise')\r\n",
    "tree_cv = cross_val_score(tree, x_trainval, y_trainval, cv = skfold, scoring = 'f1', error_score= 'raise')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print('Hasil Cross Validasi', logreg_cv)\r\n",
    "print('Hasil Mean Cross Validasi', logreg_cv.mean())\r\n",
    "print('Hasil STD Cross Validasi', logreg_cv.std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hasil Cross Validasi [0.56603774 0.43902439 0.65384615 0.53061224 0.52830189]\n",
      "Hasil Mean Cross Validasi 0.543564482325905\n",
      "Hasil STD Cross Validasi 0.06927688261828344\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print('Hasil Cross Validasi', knn_cv)\r\n",
    "print('Hasil Mean Cross Validasi', knn_cv.mean())\r\n",
    "print('Hasil STD Cross Validasi', knn_cv.std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hasil Cross Validasi [0.46153846 0.36       0.44897959 0.35897436 0.33333333]\n",
      "Hasil Mean Cross Validasi 0.3925651491365777\n",
      "Hasil STD Cross Validasi 0.05222479352609521\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "print('Hasil Cross Validasi', tree_cv)\r\n",
    "print('Hasil Mean Cross Validasi', tree_cv.mean())\r\n",
    "print('Hasil STD Cross Validasi', tree_cv.std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hasil Cross Validasi [0.66666667 0.36363636 0.55319149 0.27027027 0.48      ]\n",
      "Hasil Mean Cross Validasi 0.46675295798700056\n",
      "Hasil STD Cross Validasi 0.13917691859588774\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Perfomance in Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "logreg = LogisticRegression(solver='liblinear')\r\n",
    "logreg.fit(x_trainval, y_trainval)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "y_pred = logreg.predict(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "f1_score, recall_score, precision_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>,\n",
       " <function sklearn.metrics._classification.recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>,\n",
       " <function sklearn.metrics._classification.precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print('recall:', recall_score(y_test, y_pred)) # DEFAULT 1 ( DARI TARGET SUATU VARIABEL)\r\n",
    "print('precision:', precision_score(y_test, y_pred))\r\n",
    "print('f1:', f1_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "recall: 0.4864864864864865\n",
      "precision: 0.782608695652174\n",
      "f1: 0.6000000000000001\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       103\n",
      "           1       0.78      0.49      0.60        37\n",
      "\n",
      "    accuracy                           0.83       140\n",
      "   macro avg       0.81      0.72      0.75       140\n",
      "weighted avg       0.82      0.83      0.81       140\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "plot_roc_curve(logreg, x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x19fa2d6eac0>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "plot_precision_recall_curve(logreg, x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x19fa4a0c970>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Hyperparameter for Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\r\n",
    "    x_trainval,\r\n",
    "    y_trainval,\r\n",
    "    stratify = y_trainval,\r\n",
    "    test_size = 0.2,\r\n",
    "    random_state = 20\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "hyperparam_c = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\r\n",
    "best_score = 0\r\n",
    "val_score = []\r\n",
    "\r\n",
    "for i in hyperparam_c:\r\n",
    "    #FITTING MODEL\r\n",
    "    logreg = LogisticRegression(solver='liblinear', C = i)\r\n",
    "    logreg.fit(x_train, y_train)\r\n",
    "\r\n",
    "    # PERHITUNGAN SKOR SETIAP I/HYPERPARAM\r\n",
    "    y_pred_val = logreg.predict(x_val)\r\n",
    "    score_tmp = f1_score(y_val, y_pred_val)\r\n",
    "\r\n",
    "    # PENENTUAN SKOR TERBAIK\r\n",
    "    if score_tmp > best_score:\r\n",
    "        best_score = score_tmp\r\n",
    "        best_param = i"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print('Skor terbaik', best_score)\r\n",
    "print('Hyper terbaik', best_param)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Skor terbaik 0.6538461538461539\n",
      "Hyper terbaik 0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# perbandingan sebelum dan sesudah tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "logreg_after = LogisticRegression(solver='liblinear', C = 0.1)\r\n",
    "logreg_before = LogisticRegression(solver='liblinear', C = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "logreg_before.fit(x_trainval, y_trainval)\r\n",
    "y_pred = logreg_before.predict(x_test)\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       103\n",
      "           1       0.78      0.49      0.60        37\n",
      "\n",
      "    accuracy                           0.83       140\n",
      "   macro avg       0.81      0.72      0.75       140\n",
      "weighted avg       0.82      0.83      0.81       140\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "logreg_after.fit(x_trainval, y_trainval)\r\n",
    "y_pred = logreg_after.predict(x_test)\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       103\n",
      "           1       0.72      0.49      0.58        37\n",
      "\n",
      "    accuracy                           0.81       140\n",
      "   macro avg       0.78      0.71      0.73       140\n",
      "weighted avg       0.80      0.81      0.80       140\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Improvement pada validation score belum signifikan\r\n",
    "1. Pemilihan C kurang baik\r\n",
    "1. Bisa jadi Test Set kebetulan yang sulit diprediksi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TRAIN - VAL - TEST --> DATA SANGAT BESAR (JUTTAN) --> SPARK"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HYPERPARAMETER FOR LOGISTIC REGRESSION WITH GRID SEARCH (CROSS VALIDASI)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "hyperparam_c = {\r\n",
    "    'C':[1000, 500, 100, 50, 10, 5, 1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005],\r\n",
    "    'max_iter':[100,200,300,400,500,1000]\r\n",
    "}\r\n",
    "\r\n",
    "skfold = StratifiedKFold(n_splits = 5) # SETIAP SPLIT MEMILIKI PROPORSI DEFAULT YANG SAMA\r\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=2020)\r\n",
    "\r\n",
    "\r\n",
    "grid_search = GridSearchCV(\r\n",
    "    logreg,\r\n",
    "    param_grid = hyperparam_c,\r\n",
    "    cv = skfold,\r\n",
    "    scoring = 'f1',\r\n",
    "    n_jobs = -1\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "grid_search.fit(x_trainval, y_trainval)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(random_state=2020,\n",
       "                                          solver='liblinear'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [1000, 500, 100, 50, 10, 5, 1, 0.5, 0.1, 0.05,\n",
       "                               0.01, 0.005, 0.001, 0.0005, 0.0001, 5e-05],\n",
       "                         'max_iter': [100, 200, 300, 400, 500, 1000]},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "grid_search.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 0.05, 'max_iter': 100}"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "grid_search.best_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5563225088777649"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "hasil_cv = pd.DataFrame(grid_search.cv_results_)\r\n",
    "hasil_cv[hasil_cv['rank_test_score']>10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 1, 'max_iter': 100}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 1, 'max_iter': 200}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 1, 'max_iter': 300}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 1, 'max_iter': 400}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.005384</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 1, 'max_iter': 500}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 1, 'max_iter': 1000}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.5, 'max_iter': 100}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.5, 'max_iter': 200}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.5, 'max_iter': 300}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.5, 'max_iter': 400}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.5, 'max_iter': 500}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.5, 'max_iter': 1000}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 100}</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 200}</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 300}</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.1</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 400}</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 500}</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 1000}</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 100}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 200}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 300}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.01</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 400}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 500}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 1000}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.005, 'max_iter': 100}</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.005</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.005, 'max_iter': 200}</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.005</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.005, 'max_iter': 300}</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.005</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.005, 'max_iter': 400}</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.005, 'max_iter': 500}</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.005, 'max_iter': 1000}</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.001, 'max_iter': 100}</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.001, 'max_iter': 200}</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.001, 'max_iter': 300}</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.001</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.001, 'max_iter': 400}</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.001, 'max_iter': 500}</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.001, 'max_iter': 1000}</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.0005, 'max_iter': 100}</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.111163</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.0005, 'max_iter': 200}</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.111163</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.0005, 'max_iter': 300}</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.111163</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.0005, 'max_iter': 400}</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.111163</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.0005, 'max_iter': 500}</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.111163</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.0005, 'max_iter': 1000}</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.111163</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.0001, 'max_iter': 100}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 0.0001, 'max_iter': 200}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 0.0001, 'max_iter': 300}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 0.0001, 'max_iter': 400}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 0.0001, 'max_iter': 500}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 0.0001, 'max_iter': 1000}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 5e-05, 'max_iter': 100}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>200</td>\n",
       "      <td>{'C': 5e-05, 'max_iter': 200}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>300</td>\n",
       "      <td>{'C': 5e-05, 'max_iter': 300}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>400</td>\n",
       "      <td>{'C': 5e-05, 'max_iter': 400}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 5e-05, 'max_iter': 500}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 5e-05, 'max_iter': 1000}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "36       0.007577      0.003316         0.005785        0.002708        1   \n",
       "37       0.006980      0.002276         0.006983        0.003278        1   \n",
       "38       0.007184      0.002034         0.008574        0.003602        1   \n",
       "39       0.007183      0.002310         0.005184        0.001934        1   \n",
       "40       0.005384      0.000487         0.013954        0.014398        1   \n",
       "41       0.011019      0.001173         0.003998        0.000641        1   \n",
       "42       0.007381      0.003064         0.005999        0.002540      0.5   \n",
       "43       0.007768      0.002832         0.007379        0.002794      0.5   \n",
       "44       0.010980      0.003741         0.005633        0.002406      0.5   \n",
       "45       0.006796      0.003072         0.006184        0.002394      0.5   \n",
       "46       0.007368      0.003054         0.005587        0.002862      0.5   \n",
       "47       0.007724      0.002766         0.004831        0.001662      0.5   \n",
       "48       0.006050      0.001896         0.007595        0.003134      0.1   \n",
       "49       0.008365      0.002786         0.006383        0.003373      0.1   \n",
       "50       0.004787      0.000399         0.009794        0.002930      0.1   \n",
       "51       0.006769      0.003038         0.005985        0.002601      0.1   \n",
       "52       0.010167      0.004110         0.003990        0.000631      0.1   \n",
       "53       0.009772      0.004779         0.007605        0.003211      0.1   \n",
       "60       0.005983      0.000893         0.004214        0.001024     0.01   \n",
       "61       0.005185      0.000978         0.005386        0.001739     0.01   \n",
       "62       0.006783      0.002222         0.006382        0.003490     0.01   \n",
       "63       0.005186      0.001164         0.005385        0.001198     0.01   \n",
       "64       0.005984      0.000631         0.004987        0.001262     0.01   \n",
       "65       0.006383      0.001197         0.005386        0.001740     0.01   \n",
       "66       0.005984      0.000630         0.004789        0.000746    0.005   \n",
       "67       0.006583      0.001017         0.005385        0.002326    0.005   \n",
       "68       0.005186      0.001164         0.004388        0.000489    0.005   \n",
       "69       0.005784      0.000977         0.004189        0.000746    0.005   \n",
       "70       0.005386      0.001017         0.004787        0.000747    0.005   \n",
       "71       0.005187      0.000978         0.004787        0.001163    0.005   \n",
       "72       0.005186      0.000977         0.004787        0.000747    0.001   \n",
       "73       0.004987      0.000631         0.004189        0.000398    0.001   \n",
       "74       0.005186      0.000977         0.003990        0.000892    0.001   \n",
       "75       0.005386      0.000489         0.004787        0.001163    0.001   \n",
       "76       0.005984      0.001410         0.004588        0.000798    0.001   \n",
       "77       0.005386      0.000798         0.004388        0.000798    0.001   \n",
       "78       0.006983      0.003090         0.006381        0.002149   0.0005   \n",
       "79       0.007978      0.004503         0.004988        0.001670   0.0005   \n",
       "80       0.005584      0.001954         0.004389        0.001354   0.0005   \n",
       "81       0.006383      0.002054         0.004388        0.000798   0.0005   \n",
       "82       0.005585      0.000798         0.004588        0.001739   0.0005   \n",
       "83       0.004987      0.001093         0.005187        0.001596   0.0005   \n",
       "84       0.005585      0.002239         0.004389        0.001017   0.0001   \n",
       "85       0.005585      0.000798         0.005386        0.001954   0.0001   \n",
       "86       0.005983      0.001546         0.005586        0.001018   0.0001   \n",
       "87       0.006383      0.002410         0.003990        0.000892   0.0001   \n",
       "88       0.005585      0.000798         0.004986        0.001261   0.0001   \n",
       "89       0.005382      0.001354         0.004988        0.001548   0.0001   \n",
       "90       0.004987      0.000892         0.004189        0.000976  0.00005   \n",
       "91       0.005587      0.000799         0.007378        0.002646  0.00005   \n",
       "92       0.005984      0.002274         0.004188        0.000977  0.00005   \n",
       "93       0.006784      0.003115         0.003988        0.000631  0.00005   \n",
       "94       0.005385      0.001354         0.006184        0.003478  0.00005   \n",
       "95       0.004587      0.000490         0.004787        0.001596  0.00005   \n",
       "\n",
       "   param_max_iter                           params  split0_test_score  \\\n",
       "36            100        {'C': 1, 'max_iter': 100}           0.566038   \n",
       "37            200        {'C': 1, 'max_iter': 200}           0.566038   \n",
       "38            300        {'C': 1, 'max_iter': 300}           0.566038   \n",
       "39            400        {'C': 1, 'max_iter': 400}           0.566038   \n",
       "40            500        {'C': 1, 'max_iter': 500}           0.566038   \n",
       "41           1000       {'C': 1, 'max_iter': 1000}           0.566038   \n",
       "42            100      {'C': 0.5, 'max_iter': 100}           0.566038   \n",
       "43            200      {'C': 0.5, 'max_iter': 200}           0.566038   \n",
       "44            300      {'C': 0.5, 'max_iter': 300}           0.566038   \n",
       "45            400      {'C': 0.5, 'max_iter': 400}           0.566038   \n",
       "46            500      {'C': 0.5, 'max_iter': 500}           0.566038   \n",
       "47           1000     {'C': 0.5, 'max_iter': 1000}           0.566038   \n",
       "48            100      {'C': 0.1, 'max_iter': 100}           0.538462   \n",
       "49            200      {'C': 0.1, 'max_iter': 200}           0.538462   \n",
       "50            300      {'C': 0.1, 'max_iter': 300}           0.538462   \n",
       "51            400      {'C': 0.1, 'max_iter': 400}           0.538462   \n",
       "52            500      {'C': 0.1, 'max_iter': 500}           0.538462   \n",
       "53           1000     {'C': 0.1, 'max_iter': 1000}           0.538462   \n",
       "60            100     {'C': 0.01, 'max_iter': 100}           0.500000   \n",
       "61            200     {'C': 0.01, 'max_iter': 200}           0.500000   \n",
       "62            300     {'C': 0.01, 'max_iter': 300}           0.500000   \n",
       "63            400     {'C': 0.01, 'max_iter': 400}           0.500000   \n",
       "64            500     {'C': 0.01, 'max_iter': 500}           0.500000   \n",
       "65           1000    {'C': 0.01, 'max_iter': 1000}           0.500000   \n",
       "66            100    {'C': 0.005, 'max_iter': 100}           0.461538   \n",
       "67            200    {'C': 0.005, 'max_iter': 200}           0.461538   \n",
       "68            300    {'C': 0.005, 'max_iter': 300}           0.461538   \n",
       "69            400    {'C': 0.005, 'max_iter': 400}           0.461538   \n",
       "70            500    {'C': 0.005, 'max_iter': 500}           0.461538   \n",
       "71           1000   {'C': 0.005, 'max_iter': 1000}           0.461538   \n",
       "72            100    {'C': 0.001, 'max_iter': 100}           0.382979   \n",
       "73            200    {'C': 0.001, 'max_iter': 200}           0.382979   \n",
       "74            300    {'C': 0.001, 'max_iter': 300}           0.382979   \n",
       "75            400    {'C': 0.001, 'max_iter': 400}           0.382979   \n",
       "76            500    {'C': 0.001, 'max_iter': 500}           0.382979   \n",
       "77           1000   {'C': 0.001, 'max_iter': 1000}           0.382979   \n",
       "78            100   {'C': 0.0005, 'max_iter': 100}           0.318182   \n",
       "79            200   {'C': 0.0005, 'max_iter': 200}           0.318182   \n",
       "80            300   {'C': 0.0005, 'max_iter': 300}           0.318182   \n",
       "81            400   {'C': 0.0005, 'max_iter': 400}           0.318182   \n",
       "82            500   {'C': 0.0005, 'max_iter': 500}           0.318182   \n",
       "83           1000  {'C': 0.0005, 'max_iter': 1000}           0.318182   \n",
       "84            100   {'C': 0.0001, 'max_iter': 100}           0.000000   \n",
       "85            200   {'C': 0.0001, 'max_iter': 200}           0.000000   \n",
       "86            300   {'C': 0.0001, 'max_iter': 300}           0.000000   \n",
       "87            400   {'C': 0.0001, 'max_iter': 400}           0.000000   \n",
       "88            500   {'C': 0.0001, 'max_iter': 500}           0.000000   \n",
       "89           1000  {'C': 0.0001, 'max_iter': 1000}           0.000000   \n",
       "90            100    {'C': 5e-05, 'max_iter': 100}           0.000000   \n",
       "91            200    {'C': 5e-05, 'max_iter': 200}           0.000000   \n",
       "92            300    {'C': 5e-05, 'max_iter': 300}           0.000000   \n",
       "93            400    {'C': 5e-05, 'max_iter': 400}           0.000000   \n",
       "94            500    {'C': 5e-05, 'max_iter': 500}           0.000000   \n",
       "95           1000   {'C': 5e-05, 'max_iter': 1000}           0.000000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "36           0.439024           0.653846           0.530612   \n",
       "37           0.439024           0.653846           0.530612   \n",
       "38           0.439024           0.653846           0.530612   \n",
       "39           0.439024           0.653846           0.530612   \n",
       "40           0.439024           0.653846           0.530612   \n",
       "41           0.439024           0.653846           0.530612   \n",
       "42           0.439024           0.653846           0.530612   \n",
       "43           0.439024           0.653846           0.530612   \n",
       "44           0.439024           0.653846           0.530612   \n",
       "45           0.439024           0.653846           0.530612   \n",
       "46           0.439024           0.653846           0.530612   \n",
       "47           0.439024           0.653846           0.530612   \n",
       "48           0.444444           0.629630           0.560000   \n",
       "49           0.444444           0.629630           0.560000   \n",
       "50           0.444444           0.629630           0.560000   \n",
       "51           0.444444           0.629630           0.560000   \n",
       "52           0.444444           0.629630           0.560000   \n",
       "53           0.444444           0.629630           0.560000   \n",
       "60           0.627451           0.576271           0.576923   \n",
       "61           0.627451           0.576271           0.576923   \n",
       "62           0.627451           0.576271           0.576923   \n",
       "63           0.627451           0.576271           0.576923   \n",
       "64           0.627451           0.576271           0.576923   \n",
       "65           0.627451           0.576271           0.576923   \n",
       "66           0.603774           0.566667           0.510638   \n",
       "67           0.603774           0.566667           0.510638   \n",
       "68           0.603774           0.566667           0.510638   \n",
       "69           0.603774           0.566667           0.510638   \n",
       "70           0.603774           0.566667           0.510638   \n",
       "71           0.603774           0.566667           0.510638   \n",
       "72           0.581818           0.542373           0.363636   \n",
       "73           0.581818           0.542373           0.363636   \n",
       "74           0.581818           0.542373           0.363636   \n",
       "75           0.581818           0.542373           0.363636   \n",
       "76           0.581818           0.542373           0.363636   \n",
       "77           0.581818           0.542373           0.363636   \n",
       "78           0.588235           0.509091           0.325581   \n",
       "79           0.588235           0.509091           0.325581   \n",
       "80           0.588235           0.509091           0.325581   \n",
       "81           0.588235           0.509091           0.325581   \n",
       "82           0.588235           0.509091           0.325581   \n",
       "83           0.588235           0.509091           0.325581   \n",
       "84           0.235294           0.000000           0.000000   \n",
       "85           0.235294           0.000000           0.000000   \n",
       "86           0.235294           0.000000           0.000000   \n",
       "87           0.235294           0.000000           0.000000   \n",
       "88           0.235294           0.000000           0.000000   \n",
       "89           0.235294           0.000000           0.000000   \n",
       "90           0.000000           0.000000           0.000000   \n",
       "91           0.000000           0.000000           0.000000   \n",
       "92           0.000000           0.000000           0.000000   \n",
       "93           0.000000           0.000000           0.000000   \n",
       "94           0.000000           0.000000           0.000000   \n",
       "95           0.000000           0.000000           0.000000   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "36           0.528302         0.543564        0.069277               55  \n",
       "37           0.528302         0.543564        0.069277               55  \n",
       "38           0.528302         0.543564        0.069277               55  \n",
       "39           0.528302         0.543564        0.069277               55  \n",
       "40           0.528302         0.543564        0.069277               55  \n",
       "41           0.528302         0.543564        0.069277               55  \n",
       "42           0.518519         0.541608        0.069816               61  \n",
       "43           0.518519         0.541608        0.069816               61  \n",
       "44           0.518519         0.541608        0.069816               61  \n",
       "45           0.518519         0.541608        0.069816               61  \n",
       "46           0.518519         0.541608        0.069816               61  \n",
       "47           0.518519         0.541608        0.069816               61  \n",
       "48           0.545455         0.543598        0.059214               49  \n",
       "49           0.545455         0.543598        0.059214               49  \n",
       "50           0.545455         0.543598        0.059214               49  \n",
       "51           0.545455         0.543598        0.059214               49  \n",
       "52           0.545455         0.543598        0.059214               49  \n",
       "53           0.545455         0.543598        0.059214               49  \n",
       "60           0.490566         0.554242        0.051684               43  \n",
       "61           0.490566         0.554242        0.051684               43  \n",
       "62           0.490566         0.554242        0.051684               43  \n",
       "63           0.490566         0.554242        0.051684               43  \n",
       "64           0.490566         0.554242        0.051684               43  \n",
       "65           0.490566         0.554242        0.051684               43  \n",
       "66           0.470588         0.522641        0.054969               67  \n",
       "67           0.470588         0.522641        0.054969               67  \n",
       "68           0.470588         0.522641        0.054969               67  \n",
       "69           0.470588         0.522641        0.054969               67  \n",
       "70           0.470588         0.522641        0.054969               67  \n",
       "71           0.470588         0.522641        0.054969               67  \n",
       "72           0.444444         0.463050        0.086068               73  \n",
       "73           0.444444         0.463050        0.086068               73  \n",
       "74           0.444444         0.463050        0.086068               73  \n",
       "75           0.444444         0.463050        0.086068               73  \n",
       "76           0.444444         0.463050        0.086068               73  \n",
       "77           0.444444         0.463050        0.086068               73  \n",
       "78           0.340426         0.416303        0.111163               79  \n",
       "79           0.340426         0.416303        0.111163               79  \n",
       "80           0.340426         0.416303        0.111163               79  \n",
       "81           0.340426         0.416303        0.111163               79  \n",
       "82           0.340426         0.416303        0.111163               79  \n",
       "83           0.340426         0.416303        0.111163               79  \n",
       "84           0.000000         0.047059        0.094118               85  \n",
       "85           0.000000         0.047059        0.094118               85  \n",
       "86           0.000000         0.047059        0.094118               85  \n",
       "87           0.000000         0.047059        0.094118               85  \n",
       "88           0.000000         0.047059        0.094118               85  \n",
       "89           0.000000         0.047059        0.094118               85  \n",
       "90           0.000000         0.000000        0.000000               91  \n",
       "91           0.000000         0.000000        0.000000               91  \n",
       "92           0.000000         0.000000        0.000000               91  \n",
       "93           0.000000         0.000000        0.000000               91  \n",
       "94           0.000000         0.000000        0.000000               91  \n",
       "95           0.000000         0.000000        0.000000               91  "
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "hasil_cv[(hasil_cv['param_C'] == 1)&(hasil_cv['param_max_iter'] == 100)]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 1, 'max_iter': 100}</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.543564</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "36       0.007577      0.003316         0.005785        0.002708       1   \n",
       "\n",
       "   param_max_iter                     params  split0_test_score  \\\n",
       "36            100  {'C': 1, 'max_iter': 100}           0.566038   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "36           0.439024           0.653846           0.530612   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "36           0.528302         0.543564        0.069277               55  "
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "hasil_cv[(hasil_cv['param_C'] == 0.05)&(hasil_cv['param_max_iter'] == 100)]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00738</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.05, 'max_iter': 100}</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.556323</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "54        0.00738      0.003816         0.005809        0.002436    0.05   \n",
       "\n",
       "   param_max_iter                        params  split0_test_score  \\\n",
       "54            100  {'C': 0.05, 'max_iter': 100}           0.528302   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "54           0.530612           0.607143               0.56   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "54           0.555556         0.556323        0.028436                1  "
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perbandingan setelah dan sebelum hyperparameter tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logreg_after = LogisticRegression(solver='liblinear', C = 0.05)\r\n",
    "logreg_before = LogisticRegression(solver='liblinear', C = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "logreg_before.fit(x_trainval, y_trainval)\r\n",
    "y_pred = logreg_before.predict(x_test)\r\n",
    "print('before \\n', classification_report(y_test, y_pred))\r\n",
    "\r\n",
    "logreg_after.fit(x_trainval, y_trainval)\r\n",
    "y_pred = logreg_after.predict(x_test)\r\n",
    "print('after \\n', classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "before \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       103\n",
      "           1       0.78      0.49      0.60        37\n",
      "\n",
      "    accuracy                           0.83       140\n",
      "   macro avg       0.81      0.72      0.75       140\n",
      "weighted avg       0.82      0.83      0.81       140\n",
      "\n",
      "after \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       103\n",
      "           1       0.72      0.49      0.58        37\n",
      "\n",
      "    accuracy                           0.81       140\n",
      "   macro avg       0.78      0.71      0.73       140\n",
      "weighted avg       0.80      0.81      0.80       140\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Improvement pada validation score blm signifikan\r\n",
    "2. pemilihan hyperparam kurang baik\r\n",
    "3. bisa jadi test set kebetulan yang sulit di prediksi (random state = 2020)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7535770d6d9671ed493a7afcc4979271e63db332b4e5f67d7f7911eb0b2237d5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}